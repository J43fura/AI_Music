{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29943195908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prior to modeling, we need to convert the categorical columns, instrument and pitch, into numerical values\n",
    "# One model for the insturmetDF, and the other for notesDF\n",
    "\n",
    "\n",
    "# Generate dummy dataset - the instrumentDF\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=3, random_state=78)\n",
    "\n",
    "# Creating a DataFrame with the dummy data\n",
    "instrumentDF = pd.DataFrame(X, columns=[\"instrument\", \"note\", \"spectogram\"])\n",
    "instrumentDF[\"instrument\"] = y\n",
    "\n",
    "# Plotting the dummy data\n",
    "instrumentDF.plot.scatter(x=\"note\", y=\"spectogram\", c=\"inst\", colormap=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>note</th>\n",
       "      <th>spectogram</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.031364</td>\n",
       "      <td>-5.458210</td>\n",
       "      <td>-8.424925</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.104656</td>\n",
       "      <td>9.443778</td>\n",
       "      <td>0.417032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.398123</td>\n",
       "      <td>9.682927</td>\n",
       "      <td>-0.995417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.741012</td>\n",
       "      <td>7.413931</td>\n",
       "      <td>-0.233702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.375417</td>\n",
       "      <td>2.798941</td>\n",
       "      <td>5.806519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8.233488</td>\n",
       "      <td>-4.241836</td>\n",
       "      <td>-9.252090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5.678676</td>\n",
       "      <td>-2.896507</td>\n",
       "      <td>-8.548652</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6.158328</td>\n",
       "      <td>-5.401826</td>\n",
       "      <td>-10.874013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>7.765531</td>\n",
       "      <td>-6.611909</td>\n",
       "      <td>-8.313026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4.873720</td>\n",
       "      <td>9.282366</td>\n",
       "      <td>-1.486680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instrument      note  spectogram  Target\n",
       "0      6.031364 -5.458210   -8.424925       2\n",
       "1      6.104656  9.443778    0.417032       1\n",
       "2      6.398123  9.682927   -0.995417       1\n",
       "3      6.741012  7.413931   -0.233702       1\n",
       "4    -10.375417  2.798941    5.806519       0\n",
       "..          ...       ...         ...     ...\n",
       "995    8.233488 -4.241836   -9.252090       2\n",
       "996    5.678676 -2.896507   -8.548652       2\n",
       "997    6.158328 -5.401826  -10.874013       2\n",
       "998    7.765531 -6.611909   -8.313026       2\n",
       "999    4.873720  9.282366   -1.486680       1\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instrumentDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                60        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 214\n",
      "Trainable params: 214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  15\n",
    "hidden_nodes_layer2 = 9\n",
    "\n",
    "# Number of layers and nodes will depend how many features we have in total (including the image features)\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 2.0418 - accuracy: 0.2920\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.6364 - accuracy: 0.3307\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 75us/sample - loss: -0.2941 - accuracy: 0.3307\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 96us/sample - loss: -1.0912 - accuracy: 0.3307\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 69us/sample - loss: -2.1401 - accuracy: 0.3307\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: -3.6627 - accuracy: 0.3307\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: -5.7331 - accuracy: 0.3307\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: -8.6097 - accuracy: 0.3307\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: -12.5051 - accuracy: 0.3307\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 71us/sample - loss: -17.7819 - accuracy: 0.3307\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: -24.4622 - accuracy: 0.3307\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 102us/sample - loss: -33.1110 - accuracy: 0.3307\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 82us/sample - loss: -43.6506 - accuracy: 0.3307\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 68us/sample - loss: -55.9521 - accuracy: 0.3307\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 69us/sample - loss: -70.8098 - accuracy: 0.3307\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -87.8068 - accuracy: 0.3307\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: -107.8840 - accuracy: 0.3307\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 112us/sample - loss: -131.5624 - accuracy: 0.3307\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 78us/sample - loss: -157.6072 - accuracy: 0.3307\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: -188.0277 - accuracy: 0.3307\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 90us/sample - loss: -221.2746 - accuracy: 0.3307\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 76us/sample - loss: -258.6907 - accuracy: 0.3307\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 94us/sample - loss: -300.6977 - accuracy: 0.3307\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -345.6788 - accuracy: 0.3307\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 89us/sample - loss: -394.7725 - accuracy: 0.3307\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 81us/sample - loss: -448.3544 - accuracy: 0.3307\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 68us/sample - loss: -505.7380 - accuracy: 0.3307\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 64us/sample - loss: -566.3655 - accuracy: 0.3307\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 68us/sample - loss: -633.6285 - accuracy: 0.3307\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 82us/sample - loss: -703.9259 - accuracy: 0.3307\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 90us/sample - loss: -778.5936 - accuracy: 0.3307\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 105us/sample - loss: -858.4483 - accuracy: 0.3307\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 82us/sample - loss: -943.0400 - accuracy: 0.3307\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: -1033.3919 - accuracy: 0.3307\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 71us/sample - loss: -1126.9114 - accuracy: 0.3307\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 133us/sample - loss: -1227.1127 - accuracy: 0.3307\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -1332.7044 - accuracy: 0.3307\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: -1441.9495 - accuracy: 0.3307\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 71us/sample - loss: -1559.6164 - accuracy: 0.3307\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: -1681.1713 - accuracy: 0.3307\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: -1805.1986 - accuracy: 0.3307\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: -1938.4489 - accuracy: 0.3307\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 83us/sample - loss: -2075.2426 - accuracy: 0.3307\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 76us/sample - loss: -2219.2262 - accuracy: 0.3307\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 68us/sample - loss: -2366.8234 - accuracy: 0.3307\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 75us/sample - loss: -2524.2238 - accuracy: 0.3307\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: -2679.5085 - accuracy: 0.3307\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -2850.5987 - accuracy: 0.3307\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -3021.3915 - accuracy: 0.3307\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: -3200.6312 - accuracy: 0.3307\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 95us/sample - loss: -3384.0510 - accuracy: 0.3307\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: -3579.0427 - accuracy: 0.3307\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: -3773.0195 - accuracy: 0.3307\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 104us/sample - loss: -3982.0155 - accuracy: 0.3307\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: -4193.4774 - accuracy: 0.3307\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: -4411.6589 - accuracy: 0.3307\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 67us/sample - loss: -4640.8266 - accuracy: 0.3307\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 69us/sample - loss: -4869.1949 - accuracy: 0.3307\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 89us/sample - loss: -5107.8542 - accuracy: 0.3307\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 68us/sample - loss: -5347.5743 - accuracy: 0.3307\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: -5600.4748 - accuracy: 0.3307\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -5853.9629 - accuracy: 0.3307\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: -6120.5887 - accuracy: 0.3307\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 81us/sample - loss: -6390.6554 - accuracy: 0.3307\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 85us/sample - loss: -6668.0387 - accuracy: 0.3307\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 86us/sample - loss: -6954.4605 - accuracy: 0.3307\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 83us/sample - loss: -7245.2368 - accuracy: 0.3307\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 81us/sample - loss: -7541.1486 - accuracy: 0.3307\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: -7851.2515 - accuracy: 0.3307\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - ETA: 0s - loss: -8751.6621 - accuracy: 0.25 - 0s 77us/sample - loss: -8169.2090 - accuracy: 0.3307\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: -8485.3386 - accuracy: 0.3307\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 79us/sample - loss: -8814.6132 - accuracy: 0.3307\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 79us/sample - loss: -9149.0142 - accuracy: 0.3307\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: -9489.1130 - accuracy: 0.3307\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -9842.9019 - accuracy: 0.3307\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: -10206.0176 - accuracy: 0.3307\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: -10572.7973 - accuracy: 0.3307\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: -10954.9463 - accuracy: 0.3307\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 102us/sample - loss: -11331.1821 - accuracy: 0.3307\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 108us/sample - loss: -11727.3097 - accuracy: 0.3307\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 74us/sample - loss: -12115.9491 - accuracy: 0.3307\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 102us/sample - loss: -12521.6342 - accuracy: 0.3307\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 104us/sample - loss: -12930.0787 - accuracy: 0.3307\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 109us/sample - loss: -13344.1011 - accuracy: 0.3307\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 112us/sample - loss: -13778.6199 - accuracy: 0.3307\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 115us/sample - loss: -14212.3184 - accuracy: 0.3307\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 94us/sample - loss: -14655.8602 - accuracy: 0.3307\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 77us/sample - loss: -15101.1186 - accuracy: 0.3307\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 104us/sample - loss: -15559.8248 - accuracy: 0.3307\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 83us/sample - loss: -16022.8820 - accuracy: 0.3307\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: -16494.6615 - accuracy: 0.3307\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 101us/sample - loss: -16984.6987 - accuracy: 0.3307\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: -17472.5182 - accuracy: 0.3307\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 79us/sample - loss: -17970.5459 - accuracy: 0.3307\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: -18476.7558 - accuracy: 0.3307\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 105us/sample - loss: -18981.5321 - accuracy: 0.3307\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: -19513.1038 - accuracy: 0.3307\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 107us/sample - loss: -20035.5805 - accuracy: 0.3307\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: -20576.3754 - accuracy: 0.3307\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 103us/sample - loss: -21130.2001 - accuracy: 0.3307\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 - 0s - loss: -2.3018e+04 - accuracy: 0.3400\n",
      "Loss: -23018.0295078125, Accuracy: 0.3400000035762787\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy dataset for notesDF\n",
    "\n",
    "X2, y2 = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)\n",
    "\n",
    "\n",
    "notesDF = instrumentDF[['note', 'spectogram']].copy()\n",
    "notesDF[\"Target\"] = y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>spectogram</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.458210</td>\n",
       "      <td>-8.424925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.443778</td>\n",
       "      <td>0.417032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.682927</td>\n",
       "      <td>-0.995417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.413931</td>\n",
       "      <td>-0.233702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.798941</td>\n",
       "      <td>5.806519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-4.241836</td>\n",
       "      <td>-9.252090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-2.896507</td>\n",
       "      <td>-8.548652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-5.401826</td>\n",
       "      <td>-10.874013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-6.611909</td>\n",
       "      <td>-8.313026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9.282366</td>\n",
       "      <td>-1.486680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         note  spectogram  Target\n",
       "0   -5.458210   -8.424925       1\n",
       "1    9.443778    0.417032       0\n",
       "2    9.682927   -0.995417       0\n",
       "3    7.413931   -0.233702       1\n",
       "4    2.798941    5.806519       1\n",
       "..        ...         ...     ...\n",
       "995 -4.241836   -9.252090       1\n",
       "996 -2.896507   -8.548652       0\n",
       "997 -5.401826  -10.874013       1\n",
       "998 -6.611909   -8.313026       0\n",
       "999  9.282366   -1.486680       0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "X_scaler2 = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler2.fit(X_train2)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled2 = X_scaler2.transform(X_train2)\n",
    "X_test_scaled2 = X_scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 15)                45        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 144       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features2 = len(X_train2[0])\n",
    "hidden_nodes_layer1_2 =  15\n",
    "hidden_nodes_layer2_2= 9\n",
    "\n",
    "# Number of layers and nodes will depend how many features we have in total (including the image features)\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1_2, input_dim=number_input_features2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2_2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.7085 - accuracy: 0.5067\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 74us/sample - loss: 0.5105 - accuracy: 0.5067\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 70us/sample - loss: 0.4238 - accuracy: 0.5067\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 77us/sample - loss: 0.3842 - accuracy: 0.5067\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 96us/sample - loss: 0.3613 - accuracy: 0.5493\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 100us/sample - loss: 0.3449 - accuracy: 0.7840\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: 0.3323 - accuracy: 0.9400\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 90us/sample - loss: 0.3220 - accuracy: 0.9720\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: 0.3132 - accuracy: 0.9867\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 70us/sample - loss: 0.3057 - accuracy: 0.9920\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 71us/sample - loss: 0.2990 - accuracy: 0.9960\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.2930 - accuracy: 0.9987\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 75us/sample - loss: 0.2874 - accuracy: 0.9987\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 68us/sample - loss: 0.2822 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 103us/sample - loss: 0.2772 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.2725 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 81us/sample - loss: 0.2679 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 74us/sample - loss: 0.2635 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 97us/sample - loss: 0.2592 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: 0.2509 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.2470 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 83us/sample - loss: 0.2430 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 90us/sample - loss: 0.2392 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 86us/sample - loss: 0.2354 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: 0.2318 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 66us/sample - loss: 0.2282 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 97us/sample - loss: 0.2246 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.2212 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 89us/sample - loss: 0.2178 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: 0.2144 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 70us/sample - loss: 0.2112 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: 0.2079 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 74us/sample - loss: 0.2048 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 1.00 - 0s 82us/sample - loss: 0.2016 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: 0.1985 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: 0.1955 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 86us/sample - loss: 0.1925 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: 0.1896 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 71us/sample - loss: 0.1867 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 82us/sample - loss: 0.1839 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 87us/sample - loss: 0.1811 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: 0.1784 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: 0.1757 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: 0.1731 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: 0.1705 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 76us/sample - loss: 0.1679 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.1655 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 94us/sample - loss: 0.1630 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 69us/sample - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: 0.1582 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: 0.1559 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.1536 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 69us/sample - loss: 0.1513 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 65us/sample - loss: 0.1491 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 66us/sample - loss: 0.1469 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 66us/sample - loss: 0.1448 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.1427 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 101us/sample - loss: 0.1406 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: 0.1386 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 94us/sample - loss: 0.1366 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 102us/sample - loss: 0.1346 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: 0.1327 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 80us/sample - loss: 0.1308 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.1289 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 86us/sample - loss: 0.1271 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 71us/sample - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 67us/sample - loss: 0.1235 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 82us/sample - loss: 0.1218 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 66us/sample - loss: 0.1200 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 64us/sample - loss: 0.1184 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 65us/sample - loss: 0.1167 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 73us/sample - loss: 0.1151 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 72us/sample - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 83us/sample - loss: 0.1119 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 88us/sample - loss: 0.1103 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 89us/sample - loss: 0.1088 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 130us/sample - loss: 0.1073 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 90us/sample - loss: 0.1058 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 84us/sample - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 102us/sample - loss: 0.1029 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 122us/sample - loss: 0.1015 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 113us/sample - loss: 0.1001 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 100us/sample - loss: 0.0987 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 109us/sample - loss: 0.0974 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 91us/sample - loss: 0.0960 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 106us/sample - loss: 0.0947 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 113us/sample - loss: 0.0933 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.0919 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: 0.0868 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 117us/sample - loss: 0.0844 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 101us/sample - loss: 0.0810 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 92us/sample - loss: 0.0758 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 96us/sample - loss: 0.0684 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 97us/sample - loss: 0.0581 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 103us/sample - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 93us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 101us/sample - loss: 0.0226 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model2 = nn2.fit(X_train2,y_train2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 - 0s - loss: 0.0186 - accuracy: 1.0000\n",
      "Loss: 0.018573604501783848, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss2, model_accuracy2 = nn2.evaluate(X_test2,y_test2,verbose=2)\n",
    "print(f\"Loss: {model_loss2}, Accuracy: {model_accuracy2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
