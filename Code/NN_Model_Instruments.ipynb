{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpythondataconda68862c6cc60b49b8bda0628aae810f05",
   "display_name": "Python 3.6.9 64-bit ('PythonData': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Database Tables into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from Postgres Database\n",
    "engine = create_engine('postgresql://postgres:'+str(db_password)+'@localhost:5432/AI_Music_DB')\n",
    "\n",
    "instruments_df = pd.read_sql_table('Instruments_Spectrogram_Table',engine)\n",
    "# instruments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Convert Spectrograms from list to ndarray\n",
    "instruments_df['Spectrogram'] = instruments_df['Spectrogram'].apply(lambda x: np.array(x))\n",
    "\n",
    "type(instruments_df['Spectrogram'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data sets\n",
    "X_series = instruments_df[\"Spectrogram\"]\n",
    "y = instruments_df[\"Instrument_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "channels = 1 # number of audio channels\n",
    "spectrogram_shape = X_series[1].shape + (channels,)\n",
    "batch = spectrogram_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X into size of spectrogram and convert to ndarray\n",
    "X = np.array([i.reshape( (spectrogram_shape) ) for i in X_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode pitches\n",
    "\n",
    "le = LabelEncoder() \n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Reshape for model\n",
    "# X_train = np.array([X.reshape(20, 20, 1) for x in X_train])\n",
    "# X_test = np.array([X.reshape(20, 20, 1) for x in X_test])\n",
    "\n",
    "# onehotencoder = OneHotEncoder() \n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_train_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(22, 128, 1)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Troubleshooting queries\n",
    "type(X_train[1])\n",
    "X_train[1].shape\n",
    "# X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model\n",
    "# model = Sequential()\n",
    "# # input_shape=(128, 128, 1)\n",
    "\n",
    "# model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=spectrogram_shape))\n",
    "# model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "# model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(rate=0.5))\n",
    "\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "# \toptimizer=\"Adam\",\n",
    "# \tloss=\"categorical_crossentropy\",\n",
    "# \tmetrics=['accuracy'])\n",
    "\n",
    "# model.fit(\n",
    "# \tx=X_train, \n",
    "# \ty=y_train,\n",
    "#     epochs=12,\n",
    "#     batch_size=batch,\n",
    "#     validation_data= (X_test, y_test))\n",
    "\n",
    "# score = model.evaluate(\n",
    "# \tx=X_test,\n",
    "# \ty=y_test)\n",
    "\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(spectrogram_shape),padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(Dense(14, activation='softmax')) ########### make 14 variable for instrument num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 2184 samples, validate on 729 samples\nEpoch 1/8\n2184/2184 [==============================] - 35s 16ms/step - loss: 0.2301 - accuracy: 0.9299 - val_loss: 0.4695 - val_accuracy: 0.8505\nEpoch 2/8\n2184/2184 [==============================] - 35s 16ms/step - loss: 0.1623 - accuracy: 0.9510 - val_loss: 0.4672 - val_accuracy: 0.8519\nEpoch 3/8\n2184/2184 [==============================] - 34s 16ms/step - loss: 0.1175 - accuracy: 0.9670 - val_loss: 0.4669 - val_accuracy: 0.8532\nEpoch 4/8\n2184/2184 [==============================] - 35s 16ms/step - loss: 0.0817 - accuracy: 0.9789 - val_loss: 0.4256 - val_accuracy: 0.8724\nEpoch 5/8\n2184/2184 [==============================] - 34s 15ms/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.4552 - val_accuracy: 0.8711\nEpoch 6/8\n2184/2184 [==============================] - 34s 15ms/step - loss: 0.1537 - accuracy: 0.9547 - val_loss: 0.5073 - val_accuracy: 0.8368\nEpoch 7/8\n2184/2184 [==============================] - 34s 15ms/step - loss: 0.0728 - accuracy: 0.9799 - val_loss: 0.4954 - val_accuracy: 0.8560\nEpoch 8/8\n2184/2184 [==============================] - 34s 15ms/step - loss: 0.0448 - accuracy: 0.9895 - val_loss: 0.4589 - val_accuracy: 0.8752\n"
    }
   ],
   "source": [
    "fashion_train = fashion_model.fit(X_train, y_train_hot, batch_size=batch,epochs=8,verbose=1,validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}